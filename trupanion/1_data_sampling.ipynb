{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PolicyId</th>\n",
       "      <th>EnrollDate</th>\n",
       "      <th>CancelDate</th>\n",
       "      <th>MonthlyPremium</th>\n",
       "      <th>ClaimedAmount</th>\n",
       "      <th>PaidAmount</th>\n",
       "      <th>CustomerPaidAmount</th>\n",
       "      <th>ClaimsCount</th>\n",
       "      <th>AvgClaimAmount</th>\n",
       "      <th>AvgPaidAmount</th>\n",
       "      <th>...</th>\n",
       "      <th>VarianceCustomerPaidAmount</th>\n",
       "      <th>maxClaimAmount</th>\n",
       "      <th>minClaimAmount</th>\n",
       "      <th>medianClaimAmount</th>\n",
       "      <th>maxCustomerPaidAmount</th>\n",
       "      <th>minCustomerPaidAmount</th>\n",
       "      <th>medianCustomerPaidAmount</th>\n",
       "      <th>LastSeenDate</th>\n",
       "      <th>LOS</th>\n",
       "      <th>InsuranceStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92597</td>\n",
       "      <td>2010-12-07</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>34.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>72.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92808</td>\n",
       "      <td>2010-11-09</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>18.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>73.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93090</td>\n",
       "      <td>2010-11-11</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>23.53</td>\n",
       "      <td>762.49</td>\n",
       "      <td>329.46</td>\n",
       "      <td>433.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>254.16</td>\n",
       "      <td>109.82</td>\n",
       "      <td>...</td>\n",
       "      <td>7971.91</td>\n",
       "      <td>510.48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>152.01</td>\n",
       "      <td>510.48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>152.01</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>73.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93122</td>\n",
       "      <td>2010-11-11</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>44.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>73.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93133</td>\n",
       "      <td>2010-11-11</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>73.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93258</td>\n",
       "      <td>2010-11-11</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>21.66</td>\n",
       "      <td>33.99</td>\n",
       "      <td>30.60</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.33</td>\n",
       "      <td>10.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.33</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>66.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PolicyId EnrollDate CancelDate  MonthlyPremium  ClaimedAmount  PaidAmount  \\\n",
       "0     92597 2010-12-07 1970-01-01           34.54           0.00        0.00   \n",
       "1     92808 2010-11-09 1970-01-01           18.54           0.00        0.00   \n",
       "2     93090 2010-11-11 1970-01-01           23.53         762.49      329.46   \n",
       "3     93122 2010-11-11 1970-01-01           44.02           0.00        0.00   \n",
       "4     93133 2010-11-11 1970-01-01           32.46           0.00        0.00   \n",
       "5     93258 2010-11-11 2016-05-24           21.66          33.99       30.60   \n",
       "\n",
       "   CustomerPaidAmount  ClaimsCount  AvgClaimAmount  AvgPaidAmount  \\\n",
       "0                0.00          0.0            0.00           0.00   \n",
       "1                0.00          0.0            0.00           0.00   \n",
       "2              433.03          3.0          254.16         109.82   \n",
       "3                0.00          0.0            0.00           0.00   \n",
       "4                0.00          0.0            0.00           0.00   \n",
       "5                3.39          3.0           11.33          10.20   \n",
       "\n",
       "        ...         VarianceCustomerPaidAmount  maxClaimAmount  \\\n",
       "0       ...                               0.00            0.00   \n",
       "1       ...                               0.00            0.00   \n",
       "2       ...                            7971.91          510.48   \n",
       "3       ...                               0.00            0.00   \n",
       "4       ...                               0.00            0.00   \n",
       "5       ...                               0.00           11.33   \n",
       "\n",
       "   minClaimAmount  medianClaimAmount  maxCustomerPaidAmount  \\\n",
       "0            0.00               0.00                   0.00   \n",
       "1            0.00               0.00                   0.00   \n",
       "2          100.00             152.01                 510.48   \n",
       "3            0.00               0.00                   0.00   \n",
       "4            0.00               0.00                   0.00   \n",
       "5           11.33              11.33                  11.33   \n",
       "\n",
       "   minCustomerPaidAmount  medianCustomerPaidAmount  LastSeenDate    LOS  \\\n",
       "0                   0.00                      0.00    2016-12-31  72.81   \n",
       "1                   0.00                      0.00    2016-12-31  73.73   \n",
       "2                 100.00                    152.01    2016-12-31  73.66   \n",
       "3                   0.00                      0.00    2016-12-31  73.66   \n",
       "4                   0.00                      0.00    2016-12-31  73.66   \n",
       "5                  11.33                     11.33    2016-05-24  66.40   \n",
       "\n",
       "   InsuranceStatus  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "5                1  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "claim_df =  pd.read_csv(\"./data/ClaimLevel.csv\")\n",
    "policy_df = pd.read_csv(\"./data/PolicyLevel.csv\")\n",
    "\n",
    "\"\"\"\n",
    "                        # Data Preparation & Feature generation#\n",
    "Generate a single record per policy that retains max information possible\n",
    "\"\"\"\n",
    "claim_df['CustomerPaidAmount'] = claim_df['ClaimedAmount'] - claim_df['PaidAmount']\n",
    "claim_df_grouped = claim_df.groupby(['PolicyId'])\n",
    "claim_per_policy_df = claim_df_grouped[['ClaimedAmount', 'PaidAmount', 'CustomerPaidAmount']].sum()\n",
    "claim_per_policy_df['ClaimsCount'] = claim_df_grouped.size()\n",
    "claim_per_policy_df['AvgClaimAmount'] = claim_df_grouped[['ClaimedAmount']].mean()\n",
    "claim_per_policy_df['AvgPaidAmount'] = claim_df_grouped[['PaidAmount']].mean()\n",
    "claim_per_policy_df['AvgCustomerPaidAmount'] = claim_df_grouped[['CustomerPaidAmount']].mean()\n",
    "claim_per_policy_df['stdClaimAmount'] = claim_df_grouped[['ClaimedAmount']].std()\n",
    "claim_per_policy_df['stdPaidAmount'] = claim_df_grouped[['PaidAmount']].std()\n",
    "claim_per_policy_df['stdCustomerPaidAmount'] = claim_df_grouped[['CustomerPaidAmount']].std()\n",
    "claim_per_policy_df['VarianceClaimAmount'] = claim_df_grouped[['ClaimedAmount']].var()\n",
    "claim_per_policy_df['VariancePaidAmount'] = claim_df_grouped[['PaidAmount']].var()\n",
    "claim_per_policy_df['VarianceCustomerPaidAmount'] = claim_df_grouped[['CustomerPaidAmount']].var()\n",
    "claim_per_policy_df['maxClaimAmount'] = claim_df_grouped[['ClaimedAmount']].max()\n",
    "claim_per_policy_df['minClaimAmount'] = claim_df_grouped[['ClaimedAmount']].min()\n",
    "claim_per_policy_df['medianClaimAmount'] = claim_df_grouped[['ClaimedAmount']].median()\n",
    "claim_per_policy_df['maxCustomerPaidAmount'] = claim_df_grouped[['ClaimedAmount']].max()\n",
    "claim_per_policy_df['minCustomerPaidAmount'] = claim_df_grouped[['ClaimedAmount']].min()\n",
    "claim_per_policy_df['medianCustomerPaidAmount'] = claim_df_grouped[['ClaimedAmount']].median()\n",
    "\n",
    "policy_df = policy_df.join(claim_per_policy_df, on=['PolicyId'])\n",
    "\n",
    "# Last seen Date: CancelDate if not null else '2016-12-31' (Last date in the data set)\n",
    "policy_df['LastSeenDate'] = policy_df['CancelDate']\n",
    "policy_df['LastSeenDate'].fillna(pd.to_datetime('2016-12-31'), inplace=True)\n",
    "\n",
    "# Date conversions\n",
    "policy_df['EnrollDate'] = pd.to_datetime(policy_df['EnrollDate'])\n",
    "policy_df['CancelDate'] = pd.to_datetime(policy_df['CancelDate'])\n",
    "policy_df['LastSeenDate'] = pd.to_datetime(policy_df['LastSeenDate'])\n",
    "\n",
    "# Length of Stay \"LOS\"\n",
    "policy_df['LOS'] = ((policy_df['LastSeenDate'] - policy_df['EnrollDate'])/np.timedelta64(1, 'M'))\n",
    "policy_df = policy_df.round(decimals=2)\n",
    "\n",
    "# Insurance Status: Active means 0 else 1\n",
    "policy_df['InsuranceStatus'] = policy_df['CancelDate'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "\n",
    "# drop null values\n",
    "policy_df.dropna(axis='index', subset=['MonthlyPremium'], inplace=True)\n",
    "\n",
    "# If no claims were made then all amounts are equal to 0 instead of NULL\n",
    "for column in policy_df.columns :\n",
    "    policy_df[column].fillna(0, inplace=True)\n",
    "\n",
    "# display(claim_df.head())\n",
    "display(policy_df.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total polices 99995\n",
      "NC:C =  0.8678433921696085 : 0.13215660783039151\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "                   # Data Description #\n",
    "Churn --> 'C' --> coded as '1'\n",
    "Non-Churn --> 'NC' --> coded as '0'\n",
    "\"\"\"\n",
    "total_policies = policy_df.shape[0]\n",
    "curr_NC = policy_df[policy_df['InsuranceStatus']==0].shape[0]/float(total_policies)\n",
    "curr_C = policy_df[policy_df['InsuranceStatus']==1].shape[0]/float(total_policies)\n",
    "print(\"Total polices\", total_policies)\n",
    "print(\"NC:C = \",curr_NC, \":\", curr_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13215 86780\n"
     ]
    }
   ],
   "source": [
    "# Sampling Data\n",
    "churn_indices = policy_df[policy_df['InsuranceStatus']==1].index.values\n",
    "nonchurn_indices = policy_df[policy_df['InsuranceStatus']==0].index.values\n",
    "print(len(churn_indices), len(nonchurn_indices))\n",
    "\n",
    "def sample_train_data(num_samples=None, churn_percent=None):\n",
    "    \"\"\"\n",
    "    :param num_samples: total number of samples to return\n",
    "    :param nc: ratio of non-churn in the return data set\n",
    "    :param c: ration of churn in the return data set\n",
    "    \"\"\"\n",
    "    # check to see if nc + c = 1\n",
    "    churn_sample_space = churn_indices\n",
    "    non_churn_sample_space = nonchurn_indices\n",
    "        \n",
    "    if num_samples is None and churn_percent is None:\n",
    "        # use max samples possible (only 80% for train)\n",
    "        churn_percent = curr_C \n",
    "        num_samples = int(len(churn_indices)*0.8/churn_percent)\n",
    "    elif num_samples is None:\n",
    "        num_samples = int(len(churn_indices)*0.8/churn_percent)\n",
    "    \n",
    "    if churn_percent==None:\n",
    "        # default rate\n",
    "        churn_percent = curr_C \n",
    "    elif churn_percent > 1:\n",
    "        raise ValueError('Churn percent cannot be > 1')\n",
    "    \n",
    "    non_churn_percent = 1 - churn_percent\n",
    "    nc_samples_count = int(num_samples * non_churn_percent)\n",
    "    c_samples_count = int(num_samples * churn_percent)\n",
    "    \n",
    "    \n",
    "    # prune train indices if looking for test set\n",
    "    churn_sample_indices = np.random.choice(churn_sample_space, size=c_samples_count, replace=False)\n",
    "    nonchurn_sample_indices = np.random.choice(non_churn_sample_space, size=nc_samples_count, replace=False)\n",
    "    sample_indices = np.concatenate((churn_sample_indices, nonchurn_sample_indices))\n",
    "    # shuffle\n",
    "    np.random.shuffle(sample_indices)\n",
    "    sample = policy_df.loc[sample_indices, :]\n",
    "    return sample\n",
    "\n",
    "def sample_test_data(skip_indices):\n",
    "    \n",
    "    churn_sample_space = np.setdiff1d(churn_indices, skip_indices)\n",
    "    nonchurn_sample_space = np.setdiff1d(nonchurn_indices, skip_indices)\n",
    "    churn_sample_indices = churn_sample_space\n",
    "    nonchurn_sample_indices = np.random.choice(nonchurn_sample_space, size=len(churn_sample_indices), replace=False)\n",
    "    sample_indices = np.concatenate((churn_sample_indices, nonchurn_sample_indices))\n",
    "    # shuffle\n",
    "    np.random.shuffle(sample_indices)\n",
    "    sample = policy_df.loc[sample_indices, :]\n",
    "    return sample\n",
    "    \n",
    "# test case\n",
    "test = True\n",
    "if test == False:\n",
    "#     sample = sample_data(100, 0.8, 0.2)\n",
    "    sample = sample_data()\n",
    "    sample.head()\n",
    "    sample_total_policies = sample.shape[0]\n",
    "    NC = sample[sample['InsuranceStatus']==0].shape[0]/float(sample_total_policies)\n",
    "    C = sample[sample['InsuranceStatus']==1].shape[0]/float(sample_total_policies)\n",
    "    print(\"Total polices\", total_policies)\n",
    "    print(\"NC:C = \",NC, \":\", C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data set 1: contains NC and C in the same ratio as the given in the original data and num_samples = 0.8%\n",
    "train_set1_df = sample_train_data()\n",
    "test_set1_df = sample_test_data(skip_indices=train_set1_df.index.values)\n",
    "\n",
    "# # data set 2: NC:C = 1:1 and contains max samples possible\n",
    "train_set2_df = sample_train_data(churn_percent=0.5)\n",
    "test_set2_df = sample_test_data(skip_indices=train_set2_df.index.values)\n",
    "\n",
    "\n",
    "# # data set 3: NC:C = 1:2 and contains max samples possible\n",
    "train_set3_df = sample_train_data(churn_percent=0.66)\n",
    "test_set3_df = sample_test_data(skip_indices=train_set3_df.index.values)\n",
    "\n",
    "# # data set 4: NC:C = 2:1 and contains max samples possible\n",
    "train_set4_df = sample_train_data(churn_percent=0.33)\n",
    "test_set4_df = sample_test_data(skip_indices=train_set4_df.index.values)\n",
    "\n",
    "# # data set 5: NC:C = 4:1 and contains max samples possible\n",
    "train_set5_df = sample_train_data(churn_percent=0.20)\n",
    "test_set5_df = sample_test_data(skip_indices=train_set5_df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_columns = list(\n",
    "    set(policy_df.columns) - set(['PolicyId', 'EnrollDate', 'CancelDate', 'InsuranceStatus', 'LastSeenDate',\n",
    "#                                  'ClaimedAmount', 'PaidAmount', 'CustomerPaidAmount' , \n",
    "#                                  'AvgClaimAmount', 'AvgPaidAmount', 'stdClaimAmount', 'stdPaidAmount'\n",
    "#                                   'minClaimAmount', 'maxClaimAmount', 'medianClaimAmount'\n",
    "                                 ]))\n",
    "\n",
    "datasets  = [\n",
    "        [train_set1_df, test_set1_df],\n",
    "        [train_set2_df, test_set2_df],\n",
    "        [train_set3_df, test_set3_df],\n",
    "        [train_set4_df, test_set4_df],\n",
    "        [train_set5_df, test_set5_df]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Data set : 1\n",
      "\t Weight  0.5\n",
      "\t Test accuracy 0.50056753689\n",
      "\t tn, fp, fn, tp  [2642    1 2639    4]\n",
      "\t Weight  0.75\n",
      "\t Test accuracy 0.500756715853\n",
      "\t tn, fp, fn, tp  [2643    0 2639    4]\n",
      "\t Weight  1\n",
      "\t Test accuracy 0.5\n",
      "\t tn, fp, fn, tp  [2641    2 2641    2]\n",
      "\t Weight  1.5\n",
      "\t Test accuracy 0.50056753689\n",
      "\t tn, fp, fn, tp  [2643    0 2640    3]\n",
      "\t Weight  2\n",
      "\t Test accuracy 0.500756715853\n",
      "\t tn, fp, fn, tp  [2642    1 2638    5]\n",
      "\t Weight  3\n",
      "\t Test accuracy 0.500189178963\n",
      "\t tn, fp, fn, tp  [2642    1 2641    2]\n",
      "\t Weight  4\n",
      "\t Test accuracy 0.500378357927\n",
      "\t tn, fp, fn, tp  [2643    0 2641    2]\n",
      "train Data set : 2\n",
      "\t Weight  0.5\n",
      "\t Test accuracy 0.583238743852\n",
      "\t tn, fp, fn, tp  [1191 1452  751 1892]\n",
      "\t Weight  0.75\n",
      "\t Test accuracy 0.598183881952\n",
      "\t tn, fp, fn, tp  [1507 1136  988 1655]\n",
      "\t Weight  1\n",
      "\t Test accuracy 0.576428301173\n",
      "\t tn, fp, fn, tp  [1317 1326  913 1730]\n",
      "\t Weight  1.5\n",
      "\t Test accuracy 0.580022701476\n",
      "\t tn, fp, fn, tp  [2123  520 1700  943]\n",
      "\t Weight  2\n",
      "\t Test accuracy 0.566780174045\n",
      "\t tn, fp, fn, tp  [2200  443 1847  796]\n",
      "\t Weight  3\n",
      "\t Test accuracy 0.554672720393\n",
      "\t tn, fp, fn, tp  [2336  307 2047  596]\n",
      "\t Weight  4\n",
      "\t Test accuracy 0.523079833523\n",
      "\t tn, fp, fn, tp  [2573   70 2451  192]\n",
      "train Data set : 3\n",
      "\t Weight  0.5\n",
      "\t Test accuracy 0.533472012103\n",
      "\t tn, fp, fn, tp  [ 533 2111  356 2288]\n",
      "\t Weight  0.75\n",
      "\t Test accuracy 0.539712556732\n",
      "\t tn, fp, fn, tp  [ 694 1950  484 2160]\n",
      "\t Weight  1\n",
      "\t Test accuracy 0.541792738275\n",
      "\t tn, fp, fn, tp  [ 749 1895  528 2116]\n",
      "\t Weight  1.5\n",
      "\t Test accuracy 0.552193645991\n",
      "\t tn, fp, fn, tp  [1065 1579  789 1855]\n",
      "\t Weight  2\n",
      "\t Test accuracy 0.558623298033\n",
      "\t tn, fp, fn, tp  [1101 1543  791 1853]\n",
      "\t Weight  3\n",
      "\t Test accuracy 0.56032526475\n",
      "\t tn, fp, fn, tp  [1345 1299 1026 1618]\n",
      "\t Weight  4\n",
      "\t Test accuracy 0.566944024206\n",
      "\t tn, fp, fn, tp  [1265 1379  911 1733]\n",
      "train Data set : 4\n",
      "\t Weight  0.5\n",
      "\t Test accuracy 0.553517397882\n",
      "\t tn, fp, fn, tp  [2188  456 1905  739]\n",
      "\t Weight  0.75\n",
      "\t Test accuracy 0.553139183056\n",
      "\t tn, fp, fn, tp  [2243  401 1962  682]\n",
      "\t Weight  1\n",
      "\t Test accuracy 0.55276096823\n",
      "\t tn, fp, fn, tp  [2241  403 1962  682]\n",
      "\t Weight  1.5\n",
      "\t Test accuracy 0.551437216339\n",
      "\t tn, fp, fn, tp  [2263  381 1991  653]\n",
      "\t Weight  2\n",
      "\t Test accuracy 0.549924357035\n",
      "\t tn, fp, fn, tp  [2277  367 2013  631]\n",
      "\t Weight  3\n",
      "\t Test accuracy 0.550113464448\n",
      "\t tn, fp, fn, tp  [2289  355 2024  620]\n",
      "\t Weight  4\n",
      "\t Test accuracy 0.551815431165\n",
      "\t tn, fp, fn, tp  [2312  332 2038  606]\n",
      "train Data set : 5\n",
      "\t Weight  0.5\n",
      "\t Test accuracy 0.503972758229\n",
      "\t tn, fp, fn, tp  [2608   35 2587   56]\n",
      "\t Weight  0.75\n",
      "\t Test accuracy 0.501891789633\n",
      "\t tn, fp, fn, tp  [2623   20 2613   30]\n",
      "\t Weight  1\n",
      "\t Test accuracy 0.501891789633\n",
      "\t tn, fp, fn, tp  [2626   17 2616   27]\n",
      "\t Weight  1.5\n",
      "\t Test accuracy 0.5\n",
      "\t tn, fp, fn, tp  [2633   10 2633   10]\n",
      "\t Weight  2\n",
      "\t Test accuracy 0.500378357927\n",
      "\t tn, fp, fn, tp  [2640    3 2638    5]\n",
      "\t Weight  3\n",
      "\t Test accuracy 0.499621642073\n",
      "\t tn, fp, fn, tp  [2640    3 2642    1]\n",
      "\t Weight  4\n",
      "\t Test accuracy 0.5\n",
      "\t tn, fp, fn, tp  [2639    4 2639    4]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "                                        # RF Model #\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "i = 1\n",
    "for dataset in datasets:\n",
    "    print(\"train Data set :\", i)\n",
    "    i += 1\n",
    "    X_train = dataset[0][select_columns]\n",
    "    X_test = dataset[1][select_columns]\n",
    "    y_train = dataset[0][['InsuranceStatus']]\n",
    "    y_test = dataset[1][['InsuranceStatus']]\n",
    "    X_train, X_test = scaler.fit_transform(X_train), scaler.fit_transform(X_test)\n",
    "    for weight in [0.5, 0.75, 1, 1.5, 2, 3, 4]:\n",
    "        model = RF(n_estimators=100, class_weight={0:1,1:weight})\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predicted = model.predict(X_test)\n",
    "        print(\"\\t Weight \", weight)\n",
    "        print(\"\\t Test accuracy\",model.score(X_test, y_test))\n",
    "        print(\"\\t tn, fp, fn, tp \",confusion_matrix(y_test, y_predicted).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Data set : 1\n",
      "\t Weight on disenrolled polcies 0.5\n",
      "\t Test accuracy 0.5\n",
      "\t tn, fp, fn, tp  [2643    0 2643    0]\n",
      "\t Weight on disenrolled polcies 0.75\n",
      "\t Test accuracy 0.50056753689\n",
      "\t tn, fp, fn, tp  [2643    0 2640    3]\n",
      "\t Weight on disenrolled polcies 1\n",
      "\t Test accuracy 0.500756715853\n",
      "\t tn, fp, fn, tp  [2642    1 2638    5]\n",
      "\t Weight on disenrolled polcies 1.5\n",
      "\t Test accuracy 0.501324252743\n",
      "\t tn, fp, fn, tp  [2642    1 2635    8]\n",
      "\t Weight on disenrolled polcies 2\n",
      "\t Test accuracy 0.500945894816\n",
      "\t tn, fp, fn, tp  [2640    3 2635    8]\n",
      "\t Weight on disenrolled polcies 3\n",
      "\t Test accuracy 0.50170261067\n",
      "\t tn, fp, fn, tp  [2637    6 2628   15]\n",
      "\t Weight on disenrolled polcies 4\n",
      "\t Test accuracy 0.503216042376\n",
      "\t tn, fp, fn, tp  [2632   11 2615   28]\n",
      "train Data set : 2\n",
      "\t Weight on disenrolled polcies 0.5\n",
      "\t Test accuracy 0.50170261067\n",
      "\t tn, fp, fn, tp  [2640    3 2631   12]\n",
      "\t Weight on disenrolled polcies 0.75\n",
      "\t Test accuracy 0.605372682558\n",
      "\t tn, fp, fn, tp  [2010  633 1453 1190]\n",
      "\t Weight on disenrolled polcies 1\n",
      "\t Test accuracy 0.593832765796\n",
      "\t tn, fp, fn, tp  [1285 1358  789 1854]\n",
      "\t Weight on disenrolled polcies 1.5\n",
      "\t Test accuracy 0.557132046916\n",
      "\t tn, fp, fn, tp  [ 616 2027  314 2329]\n",
      "\t Weight on disenrolled polcies 2\n",
      "\t Test accuracy 0.532160423761\n",
      "\t tn, fp, fn, tp  [ 325 2318  155 2488]\n",
      "\t Weight on disenrolled polcies 3\n",
      "\t Test accuracy 0.517404464624\n",
      "\t tn, fp, fn, tp  [ 135 2508   43 2600]\n",
      "\t Weight on disenrolled polcies 4\n",
      "\t Test accuracy 0.510594021945\n",
      "\t tn, fp, fn, tp  [  81 2562   25 2618]\n",
      "train Data set : 3\n",
      "\t Weight on disenrolled polcies 0.5\n",
      "\t Test accuracy 0.59171709531\n",
      "\t tn, fp, fn, tp  [1263 1381  778 1866]\n",
      "\t Weight on disenrolled polcies 0.75\n",
      "\t Test accuracy 0.553895612708\n",
      "\t tn, fp, fn, tp  [ 593 2051  308 2336]\n",
      "\t Weight on disenrolled polcies 1\n",
      "\t Test accuracy 0.532904689864\n",
      "\t tn, fp, fn, tp  [ 283 2361  109 2535]\n",
      "\t Weight on disenrolled polcies 1.5\n",
      "\t Test accuracy 0.515506807867\n",
      "\t tn, fp, fn, tp  [ 117 2527   35 2609]\n",
      "\t Weight on disenrolled polcies 2\n",
      "\t Test accuracy 0.508131618759\n",
      "\t tn, fp, fn, tp  [  63 2581   20 2624]\n",
      "\t Weight on disenrolled polcies 3\n",
      "\t Test accuracy 0.503025718608\n",
      "\t tn, fp, fn, tp  [  22 2622    6 2638]\n",
      "\t Weight on disenrolled polcies 4\n",
      "\t Test accuracy 0.50189107413\n",
      "\t tn, fp, fn, tp  [  10 2634    0 2644]\n",
      "train Data set : 4\n",
      "\t Weight on disenrolled polcies 0.5\n",
      "\t Test accuracy 0.500378214826\n",
      "\t tn, fp, fn, tp  [2644    0 2642    2]\n",
      "\t Weight on disenrolled polcies 0.75\n",
      "\t Test accuracy 0.500756429652\n",
      "\t tn, fp, fn, tp  [2641    3 2637    7]\n",
      "\t Weight on disenrolled polcies 1\n",
      "\t Test accuracy 0.501512859304\n",
      "\t tn, fp, fn, tp  [2635    9 2627   17]\n",
      "\t Weight on disenrolled polcies 1.5\n",
      "\t Test accuracy 0.581505295008\n",
      "\t tn, fp, fn, tp  [2154  490 1723  921]\n",
      "\t Weight on disenrolled polcies 2\n",
      "\t Test accuracy 0.602874432678\n",
      "\t tn, fp, fn, tp  [1409 1235  865 1779]\n",
      "\t Weight on disenrolled polcies 3\n",
      "\t Test accuracy 0.564107413011\n",
      "\t tn, fp, fn, tp  [ 687 1957  348 2296]\n",
      "\t Weight on disenrolled polcies 4\n",
      "\t Test accuracy 0.538199697428\n",
      "\t tn, fp, fn, tp  [ 374 2270  172 2472]\n",
      "train Data set : 5\n",
      "\t Weight on disenrolled polcies 0.5\n",
      "\t Test accuracy 0.5\n",
      "\t tn, fp, fn, tp  [2643    0 2643    0]\n",
      "\t Weight on disenrolled polcies 0.75\n",
      "\t Test accuracy 0.500189178963\n",
      "\t tn, fp, fn, tp  [2643    0 2642    1]\n",
      "\t Weight on disenrolled polcies 1\n",
      "\t Test accuracy 0.500378357927\n",
      "\t tn, fp, fn, tp  [2642    1 2640    3]\n",
      "\t Weight on disenrolled polcies 1.5\n",
      "\t Test accuracy 0.500378357927\n",
      "\t tn, fp, fn, tp  [2640    3 2638    5]\n",
      "\t Weight on disenrolled polcies 2\n",
      "\t Test accuracy 0.50056753689\n",
      "\t tn, fp, fn, tp  [2637    6 2634    9]\n",
      "\t Weight on disenrolled polcies 3\n",
      "\t Test accuracy 0.579076806659\n",
      "\t tn, fp, fn, tp  [2138  505 1720  923]\n",
      "\t Weight on disenrolled polcies 4\n",
      "\t Test accuracy 0.591373439274\n",
      "\t tn, fp, fn, tp  [1398 1245  915 1728]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "                                        # Logistic Model #\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "i = 1\n",
    "for dataset in datasets:\n",
    "    print(\"train Data set :\", i)\n",
    "    i += 1\n",
    "    X_train = dataset[0][select_columns]\n",
    "    X_test = dataset[1][select_columns]\n",
    "    y_train = dataset[0][['InsuranceStatus']]\n",
    "    y_test = dataset[1][['InsuranceStatus']]\n",
    "    X_train, X_test = scaler.fit_transform(X_train), scaler.fit_transform(X_test)\n",
    "    for weight in [0.5, 0.75, 1, 1.5, 2, 3, 4]:\n",
    "        point_weights = dataset[0].InsuranceStatus.apply(lambda x: 1 if x == 0 else weight)\n",
    "        model = LogisticRegression(penalty='l1',)\n",
    "        model.fit(X_train, y_train, point_weights)\n",
    "        y_predicted = model.predict(X_test)\n",
    "        print(\"\\t Weight on disenrolled polcies\", weight)\n",
    "        print(\"\\t Test accuracy\",model.score(X_test, y_test))\n",
    "        print(\"\\t tn, fp, fn, tp \",confusion_matrix(y_test, y_predicted).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Data set : 1\n",
      "\t Train 0.869343467173\n",
      "\t tn, fp, fn, tp  [2640    3 2626   17]\n",
      "train Data set : 2\n",
      "\t Train 0.624385168369\n",
      "\t tn, fp, fn, tp  [1670  973 1030 1613]\n",
      "train Data set : 3\n",
      "\t Train 0.692077168009\n",
      "\t tn, fp, fn, tp  [ 504 2140  215 2429]\n",
      "train Data set : 4\n",
      "\t Train 0.693241766818\n",
      "\t tn, fp, fn, tp  [2540  104 2354  290]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "                                        # neural nets Model #\n",
    "\"\"\"\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "datasets  = [\n",
    "        [train_set1_df, test_set1_df],\n",
    "        [train_set2_df, test_set2_df],\n",
    "        [train_set3_df, test_set3_df],\n",
    "        [train_set4_df, test_set4_df]\n",
    "        ]\n",
    "\n",
    "i = 1\n",
    "for dataset in datasets:\n",
    "    print(\"train Data set :\", i)\n",
    "    i += 1\n",
    "    X_train = dataset[0][select_columns]\n",
    "    X_test = dataset[1][select_columns]\n",
    "    y_train = dataset[0][['InsuranceStatus']]\n",
    "    y_test = dataset[1][['InsuranceStatus']]\n",
    "    X_train, X_test = scaler.fit_transform(X_train), scaler.fit_transform(X_test)\n",
    "    model = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(16, 32, 24, 8), random_state=1, \n",
    "                         activation='relu')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predicted = model.predict(X_test)\n",
    "    print(\"\\t Train\",model.score(X_train, y_train))\n",
    "    print(\"\\t tn, fp, fn, tp \",confusion_matrix(y_test, y_predicted).ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train sets\n",
      "79996\n",
      "21144\n",
      "16017\n",
      "32035\n",
      "52860\n",
      "Length of test sets\n",
      "5286\n",
      "5286\n",
      "5288\n",
      "5288\n",
      "5286\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train sets\")\n",
    "print(len(train_set1_df))\n",
    "print(len(train_set2_df))\n",
    "print(len(train_set3_df))\n",
    "print(len(train_set4_df))\n",
    "print(len(train_set5_df))\n",
    "print(\"Length of test sets\")\n",
    "print(len(test_set1_df))\n",
    "print(len(test_set2_df))\n",
    "print(len(test_set3_df))\n",
    "print(len(test_set4_df))\n",
    "print(len(test_set5_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99995\n"
     ]
    }
   ],
   "source": [
    "print(len(policy_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
